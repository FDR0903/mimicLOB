{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to fit QRM intensities from EURONEXT data\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd, datetime as dt, numpy as np, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import sys\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "# Display options\n",
    "thisnotebooksys = sys.stdout\n",
    "pd.set_option('display.width', 1000)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Description\n",
    "\n",
    "- DTIME : le timestamp de l'ordre\n",
    "- ORDER_ID : l'identifiant de l'ordre\n",
    "- PRICE \n",
    "- QTY\n",
    "- ORDER_SIDE\n",
    "- ORDER_SIDE\n",
    "- ORDER_TYPE :  <br>1 pour Market Order; <br>2 pour Limit Order; <br>q pour Quote <br> W pour Market On Open;\n",
    "- ACTION_TYPE : <br> I = limit order insertion (passive); <br> C = limit order cacnellations; <br> R = replace order that lose priority; <br> r = replace order that keeps priority; <br> S = replace order that makes the order aggressive (give rise to trade); <br> T = aggressive order (give rise to trade)\n",
    "- MATCH_STRATEGY : True/False\n",
    "- IS_OPEN_TRADE :  True/False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= 'day20160428'\n",
    "df = pd.read_hdf(Path(r'..\\data', f'{filename}.h5'))\n",
    "\n",
    "# Clean Data\n",
    "df = df[((df.DTIME.dt.time < dt.time(21)) & (df.DTIME.dt.time > dt.time(6)))] #no auction\n",
    "\n",
    "df = df[df.ASK0!=0]\n",
    "df = df[df.BID0!=0]\n",
    "df = df[((df.PRICE < 5000) & (df.PRICE > 4000))]\n",
    "df = df[((df.ASK0 < 5000) & (df.ASK0 > 4000))]\n",
    "df = df[((df.BID0 < 5000) & (df.BID0 > 4000))]\n",
    "\n",
    "# get the first future\n",
    "df = df[df.PRODUCT_NAME=='JFFCE160500000F']\n",
    "\n",
    "# ticksize\n",
    "ticksize = 0.5\n",
    "\n",
    "#Construct columns for better vizu\n",
    "newcols = ['DTIME', 'ORDER_ID', 'PRICE', 'QTY', \n",
    "           'ORDER_SIDE', 'ORDER_TYPE', 'ACTION_TYPE'] \n",
    "\n",
    "# df.loc[:, newcols+newcols2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of queues for fitting\n",
    "nbQueues = 4\n",
    "\n",
    "BIDASK_COLS = []\n",
    "BIDASK_COLS2 = []\n",
    "for i in range(nbQueues-1, -1, -1):\n",
    "    BIDASK_COLS += [f'BID{i}']\n",
    "    BIDASK_COLS2 += [f'BID{i}', f'BID{i}_QTY']\n",
    "for i in range(nbQueues):\n",
    "    BIDASK_COLS += [f'ASK{i}']\n",
    "    BIDASK_COLS2 += [f'ASK{i}', f'ASK{i}_QTY']\n",
    "    \n",
    "df = df.loc[:, ['DTIME', 'ORDER_ID', 'PRICE', 'QTY', 'ORDER_SIDE', 'ORDER_TYPE', 'ACTION_TYPE'] + BIDASK_COLS2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define events : type & queue of each event \n",
    "#### Queue on which each event is considered on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# specify the limit of the event\n",
    "AqueuePricesCols = [col for col in df.columns if (('ASK' in col) & ('QTY' not in col))]\n",
    "BqueuePricesCols = [col for col in df.columns if (('BID' in col) & ('QTY' not in col))]\n",
    "\n",
    "# get the queue of the event\n",
    "def getQueue(x):\n",
    "    if x['ORDER_SIDE'] == 'B':\n",
    "        return (x['PRICE']-x[BqueuePricesCols]).abs().astype(float).idxmin() if 0 in (x['PRICE']-x[BqueuePricesCols]).values else np.nan\n",
    "    else:\n",
    "        return (x['PRICE']-x[AqueuePricesCols]).abs().astype(float).idxmin() if 0 in (x['PRICE']-x[AqueuePricesCols]).values else np.nan\n",
    "\n",
    "df['eventQueue'] = df.apply(getQueue, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on queues that we want\n",
    "df = df[df.eventQueue.isin(BIDASK_COLS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# for replace orders, define previous queue and previous quantity\n",
    "df['PREV_ORDER_PRICE'] = 0\n",
    "df['PREV_ORDER_QTY']   = 0\n",
    "df['PREV_ORDER_QUEUE'] = 0\n",
    "\n",
    "# only orders with a modification that loses priority\n",
    "listorders = df[df.ACTION_TYPE=='R'].ORDER_ID.unique()\n",
    "\n",
    "#'PREV_ORDER_QUEUE'\n",
    "for order_id in listorders:\n",
    "    df.loc[df[df.ORDER_ID==order_id].index, ['PREV_ORDER_PRICE', 'PREV_ORDER_QTY']] = df.loc[df[df.ORDER_ID==order_id].index, ['PRICE', 'QTY']].shift(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define prev order queue\n",
    "def getPrevQueue(x):\n",
    "    if x['ORDER_SIDE'] == 'B':\n",
    "        return (x['PREV_ORDER_PRICE']-x[BqueuePricesCols]).abs().astype(float).idxmin() if 0 in (x['PREV_ORDER_PRICE']-x[BqueuePricesCols]).values else np.nan\n",
    "    else:\n",
    "        return (x['PREV_ORDER_PRICE']-x[AqueuePricesCols]).abs().astype(float).idxmin() if 0 in (x['PREV_ORDER_PRICE']-x[AqueuePricesCols]).values else np.nan\n",
    "\n",
    "df.loc[df[df.ACTION_TYPE=='R'].index, 'PREV_ORDER_QUEUE'] = df[df.ACTION_TYPE=='R'].apply(getPrevQueue, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# define type of event (0 for removal and 1 for addition of liquidity)\n",
    "# first, removal of liquidity\n",
    "df.loc[df[df.ORDER_TYPE==1].index, 'eventType'] = 0\n",
    "df.loc[df[((df.ORDER_TYPE=='2') & (df.ACTION_TYPE=='I'))].index, 'eventType'] = 1 # limit order\n",
    "df.loc[df[((df.ORDER_TYPE=='2') & (df.ACTION_TYPE=='C'))].index, 'eventType'] = 0 # cancelation \n",
    "df.loc[df[((df.ORDER_TYPE=='2') & (df.ACTION_TYPE=='r'))].index, 'eventType'] = 0 # replace with quantity diminition\n",
    "df.loc[df[((df.ORDER_TYPE=='2') & (df.ACTION_TYPE=='S'))].index, 'eventType'] = 0 # market order\n",
    "df.loc[df[((df.ORDER_TYPE=='2') & (df.ACTION_TYPE=='T'))].index, 'eventType'] = 0 # market order\n",
    "\n",
    "# duplicate replace orders with actgion type == R\n",
    "# they are considered a liquidity removal on their previous queue\n",
    "# they are considered a liquidity addition on their current queue\n",
    "newdf = df[df.ACTION_TYPE=='R'].copy()\n",
    "newdf['eventQueue'] = df['PREV_ORDER_QUEUE']\n",
    "newdf['eventType'] = 0 # liquidity removal on previous queue\n",
    "df.loc[df[((df.ORDER_TYPE=='2') & (df.ACTION_TYPE=='R'))].index, 'eventType'] = 1 # liquidity addition on current queue\n",
    "df = pd.concat([df, newdf]).sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waiting Times between events on the same queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['WAITING_TIME'] = 0\n",
    "for queue in BIDASK_COLS:\n",
    "    df.loc[df[df.eventQueue==queue].index, 'WAITING_TIME'] = df.loc[df[df.eventQueue==queue].index, 'DTIME'].diff(1).apply(lambda x: x.total_seconds()).fillna(0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REF PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# nb of ticks between best limits\n",
    "df['nbticksBetweenBestLimits'] = (df['ASK0'] - df['BID0'])/ticksize\n",
    "\n",
    "# define ref price\n",
    "df_midprice = (df['BID0'] + df['ASK0'])/2\n",
    "df_mid1 = df_midprice + ticksize/2\n",
    "df_mid2 = df_midprice - ticksize/2\n",
    "df_refprice_odd = df_midprice * (df['nbticksBetweenBestLimits']%2)\n",
    "\n",
    "# define ref price\n",
    "df['refprice'] = df_refprice_odd\n",
    "\n",
    "lastprice = df_midprice.iloc[0]\n",
    "for (i, idx) in enumerate(list(df.index)):\n",
    "    # odd values\n",
    "    if df.at[idx, 'refprice'] == 0:\n",
    "        df.at[idx, 'refprice'] = df_mid1.at[idx] if np.abs(lastprice-df_mid1.at[idx]) < np.abs(lastprice-df_mid2.at[idx]) else df_mid2.at[idx]\n",
    "    lastprice = df.at[idx, 'refprice']\n",
    "#     if i%100000==1:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalcountEvents2 = df['eventQueue'].value_counts()\n",
    "totalcountEvents2.loc[BIDASK_COLS]\n",
    "SizesOfEvents = df[['eventQueue', 'QTY']].groupby('eventQueue').sum()\n",
    "dfAES = SizesOfEvents\n",
    "dfAES.columns = ['sizes']\n",
    "dfAES.loc[BIDASK_COLS, 'counts'] = totalcountEvents2.loc[BIDASK_COLS]\n",
    "dfAES = dfAES.loc[BIDASK_COLS]\n",
    "AES = (dfAES['sizes'] / dfAES['counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# construct new df with data that we want : event type, event time, event queue, event's waiting time, every queue's size\n",
    "df_lambdas = df.loc[:, ['DTIME', 'eventType', 'eventQueue', 'WAITING_TIME'] + [f'{col}_QTY' for col in BIDASK_COLS]]\n",
    "df_lambdas = df_lambdas[df_lambdas.eventQueue.isin(BIDASK_COLS)]\n",
    "df_lambdas.columns = ['DTIME', 'eventType', 'eventQueue', 'WAITING_TIME'] + BIDASK_COLS\n",
    "\n",
    "# devide sizes by corresponding AES's\n",
    "for col in BIDASK_COLS:\n",
    "    df_lambdas[col] = (df_lambdas[col] / AES[col]).apply(np.ceil) #rounded up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambdas.to_hdf(f'df_lambdas_{filename}.h5', 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambdas = pd.concat([pd.read_hdf(f'df_lambdas_{filename}.h5') for filename in ['day20160425', 'day20160426', 'day20160427', 'day20160428', 'day20160429']])\n",
    "len(df_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lambda for all queues, for each state of the queue\n",
    "Lambda_plus = pd.DataFrame({'queue' : BIDASK_COLS}).set_index('queue').T\n",
    "Lambda_minus = pd.DataFrame({'queue' : BIDASK_COLS}).set_index('queue').T\n",
    "\n",
    "allQuantities = np.sort(pd.unique(df_lambdas.loc[:, BIDASK_COLS].values.ravel()))\n",
    "\n",
    "# until 40\n",
    "allQuantities = [qtty for qtty in allQuantities if qtty<=40]\n",
    "\n",
    "ALPHAs = df_lambdas.groupby('eventQueue').WAITING_TIME.mean() #df_lambdas[df_lambdas.eventQueue==curr_queue].WAITING_TIME.mean()\n",
    "lendf = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for qtty in allQuantities:\n",
    "    Lambda_plus.loc[qtty] = np.nan\n",
    "    Lambda_minus.loc[qtty] = np.nan\n",
    "\n",
    "    for curr_queue in BIDASK_COLS:\n",
    "        ALPHA = ALPHAs[curr_queue]\n",
    "        tmpdf = df_lambdas[((df_lambdas.eventQueue==curr_queue) & (df_lambdas[curr_queue]==qtty))]\n",
    "        \n",
    "        len1 = len(tmpdf[tmpdf.eventType==1])\n",
    "        len0 = len(tmpdf[tmpdf.eventType==0])\n",
    "        len2 = len(tmpdf)\n",
    "        \n",
    "        if len2 == 0:\n",
    "            Lambda_plus.at[qtty, curr_queue] = np.nan\n",
    "            Lambda_minus.at[qtty, curr_queue] = np.nan\n",
    "        else:\n",
    "            Lambda_plus.at[qtty, curr_queue] = (len1/len2) / ALPHA\n",
    "            Lambda_minus.at[qtty, curr_queue] = (len0/len2) / ALPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Lambda_plus.fillna(0).BID0/Lambda_minus.fillna(0).BID0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10), (ax11, ax12)) = plt.subplots(6,2,figsize=(25,40), sharex=False)\n",
    "\n",
    "# Ref prices distribution\n",
    "countRefPrices = df.groupby('refprice')['refprice'].count()\n",
    "ax1.bar(countRefPrices.index, countRefPrices.values); ax1.legend(['reference price distribution'])\n",
    "\n",
    "# Ref Price evolution\n",
    "df.refprice.plot(ax=ax2); ax2.legend(['Ref Price'])\n",
    "\n",
    "# AES distribtion\n",
    "ax3.bar(AES.index, AES.values); ax3.legend(['Average Event Size per Queue']); \n",
    "\n",
    "# Waiting times distribution\n",
    "WT = df[['WAITING_TIME', 'eventQueue']].groupby('eventQueue').mean().loc[BIDASK_COLS]\n",
    "ax4.bar(WT.index, WT.values[:,0]); ax4.legend(['Average Waiting Time']); \n",
    "\n",
    "# evolution of intensities depending on AES for best limits\n",
    "Lambda_plus.loc[:, 'BID0'].fillna(0).plot(ax=ax5, linestyle='-.', marker='o'); ax5.legend(['Liquidity Addition - First Bid Limit']); \n",
    "Lambda_plus.loc[:, 'ASK0'].fillna(0).plot(ax=ax6, linestyle='-.', marker='o'); ax6.legend(['Liquidity Addition - First Ask Limit']); \n",
    "\n",
    "Lambda_minus.loc[:, 'BID0'].fillna(0).plot(ax=ax7, linestyle='-.', marker='o'); ax7.legend(['Liquidity Removal - First Ask Limit']); \n",
    "Lambda_minus.loc[:, 'ASK0'].fillna(0).plot(ax=ax8, linestyle='-.', marker='o'); ax8.legend(['Liquidity Removal - First Bid Limit']); \n",
    "\n",
    "# evolution of intensities depending on AES for second limits\n",
    "Lambda_plus.loc[:, 'BID1'].fillna(0).plot(ax=ax9, linestyle='-.', marker='o'); ax9.legend(['Liquidity Addition - Second Bid Limit']); \n",
    "Lambda_plus.loc[:, 'ASK1'].fillna(0).plot(ax=ax10, linestyle='-.', marker='o'); ax10.legend(['Liquidity Addition - Second Ask Limit']); \n",
    "\n",
    "Lambda_minus.loc[:, 'BID1'].fillna(0).plot(ax=ax11, linestyle='-.', marker='o'); ax11.legend(['Liquidity Removal - Second Bid Limit']); \n",
    "Lambda_minus.loc[:, 'ASK1'].fillna(0).plot(ax=ax12, linestyle='-.', marker='o'); ax12.legend(['Liquidity Removal - Second Ask Limit']); \n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickelize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda_plus.T.to_pickle(r'..\\data\\Lambda_plus.pkl')\n",
    "Lambda_minus.T.to_pickle(r'..\\data\\Lambda_minus.pkl')\n",
    "AES.to_pickle(r'..\\data\\event_sizes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
